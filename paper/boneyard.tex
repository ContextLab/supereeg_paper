
as $\delta$, $\theta$, and $\alpha$, have been implicated in processing modes
which span large swaths of cortical regions and are thought to serve the purpose
of integration across many cortical sites ~\citep{Knya12}. Higher frequency
oscillations such as $\beta$ and $\gamma$, are more limited to topographic areas
~\citep{Nune95}, and are modulated by slow oscillations hierarchically
~\citep{EngeEtal10}. Using the frequency-specific reconstruction accuracies, we
followed the process outlined in Fig.~\ref{fig:informap}C, to obtain the most
informative locations for each frequency.  When we examined the intersection
between the top 10\% most informative voxels across the two datasets for each
bandpassed frequency, we found a somewhat consistent hierarchical structure (see
Fig.~\ref{fig:networks}E).




; $\theta$ activity
in frontal regions have been implicated in memory
consolidation~\citep{NishEtal09} and integration~\citep{BackEtal16}; parietal
and occipital $\alpha$ activity has been implicated in attention
modulation~\citep[e.g., see][]{Klim12}; $\beta$ activity in motor cortex have
been implicated in motor control and processing~\citep{BrovEtal04, KoelEtal08,
RubiEtal06}; and occipital $\gamma$ activity has been implicated in visual
attention and visual processing~\citep{ZhouEtal16, TallEtal05, FrieEtal07}.




%next: neurosynth

%%%%STOPPED HERE



We then wondered which networks were involved in each of these
frequency-specific intersecting regions.  To better understand the networks
involved we colored the regions (Fig.~\ref{fig:networks}A) based on the network
parcellation ~\citep[using $k$=7;][]{YeoEtal11}} (Fig.~\ref{fig:networks}D) and
calculated the proportion of each of those networks (Fig.~\ref{fig:networks}B).
Consistent with the idea outlined above, we found networks most involved in the
lowest frequency band, $\delta$, were networks involved integration and global
processing (specifically the dorsal attention ~\citep{MarzEtal13}, default mode,
and frontoparietal networks).  Although these networks are also seen in the
$\theta$ intersection, they are less proportionally to the visual network.
Alpha power is consistently modulated in EEG studies of attention and
visuo-motor ~\citep{MantEtal07, MarzEtal13}, and we similarly found a high
proportion of visual, somatomotor, and dorsal attention networks within this
band.  We found $\beta$ intersections to predominantly consist of somatomotor
network, in line with~\citep{RittEtal09, VaneEtal11}.  Also accordant with
heavily cited literature~\citep{FrieEtal07}, the network most predominant in the
$\gamma$ intersection was the visual network.  Lastly, broadband power was found
predominantly in frontoparietal and default mode networks, consistent with
~\citep{OssaEtal11}.


% old discussion section
Human \textit{SuperEEG}\footnote{The term ``SuperEEG'' was coined by
    Robert J. Sawyer in his popular science fiction novel \textit{The
      Terminal Experiment}~\cite{Sawy95}.  SuperEEG is a fictional
    technology that measures ongoing
  neural activity throughout the entire living human brain with perfect
  precision and at arbitrarily high spatiotemporal resolution.}


%DISCUSSION POINTS
%recap main approach
SuperEEG infers full-brain activity patterns by leveraging
correlations in those patterns of brain activity within and across people.  Although
the approach may, in principle, be used to infer brain activity
\textit{anywhere} in the brain, the inferences perform slightly better for
regions with dense electrode sampling across patients.  (Taken to the logical extreme, we could not hope to accurately recover activity patterns from brain areas where no recordings existed from any patient.)   As more data
are included in the inference procedure, this suggests that reconstruction accuracy should improve.

%why does it work?  redundancy of brain
A fundamental assumption of the SuperEEG algorithm is that the data
covariance matrix is stable over time and across people.  This is a
useful simplification.  However, a growing body of evidence from the
fMRI community suggests that the data covariance matrix changes in
meaningful ways over time (for example, the data covariance matrix
changes from moment-to-moment during story listening, serving as a
unique ``fingerprint'' for each moment of the story; further, these
task-driven timepoint-specific covariance fingerprints appear to be
largely preserved across people~\cite{SimoEtal16, MannEtal18}).  These
findings indicate that the full-brain covariance matrix is not stable
over time.  Other recent work has shown that people's resting state
connectivity matrices may be used to uniquely identify individuals and
predict fluid intelligence scores~\cite{FinnEtal15}.  This indicates
that the full-brain covariance matrix is not stable across people.  If
the fundamental stability assumptions that SuperEEG relies on are
violated, how can the SuperEEG algorithm still accurately recover LFP
data?  It is important to recognize that the fact that variability
(over time or across people) is predictive (e.g., of cognitive states
during story listening or fluid intelligence scores) does not
necessarily mean that this variability is large in magnitude.  Rather,
we have long known that brain structure is tightly preserved across
individuals (and over time, at least on the timescale of typical
clinical and experimental recording sessions), and any functional
changes must occur within the framework of the underlying structural
anatomy.  Nevertheless, one could imagine future improvements to the
SuperEEG approach that leverage resting state fMRI or structural data
[e.g., diffusion tensor imaging (DTI)] to estimate Bayesian priors over
the correlation matrices inferred, in the current framing, using only
ECoG data.  Further, relaxing the assumption that the covariance
matrix is stable (over time and/or across people), and/or
incorporating more detailed brain conductance models (e.g., informed
by structural MRI scans) may improve the predictive performance of the
approach.



%This technique relies on recordings from many patients performing the
%same basic cognitive task.  To what extent do these findings
%generalize across studies?  For example, could one combine recordings
%from several studies to improve our ability to reconstruct neural
%activity?
One potential limitation of the SuperEEG approach is that the above
assumption of covariance stability across people may be violated even
more if different patients are performing different cognitive tasks.
To understand of the extent to which the current findings generalize across
cognitive tasks, we replicated our initial findings using a dataset in which patients participated in two tasks, and limited the training data to either within task, across task, or using both tasks. Since we found the most accurate reconstructions using task-specific data, this would suggest building up new databases for estimating each task-specific covariance
matrix.  Or, using a more sophisticated approach, one could create a
hierarchical model whereby each task-specific covariance matrix was
modeled as a perturbation of a ``global'' task-unspecific covariance
matrix (which could in turn be informed by fMRI or DTI data).
% Alternatively, if the covariance matrix is stable across tasks, this would
% suggest that recordings from multiple studies could be combined to
% improve the overall reconstruction accuracy.

A second potential limitation of the SuperEEG approach is that it
does not provide a natural means of estimating the precise timing of
single-neuron action potentials.  Prior work has shown that gamma band
and broadband activity in the LFP may be used to estimate the firing
rates of neurons that underly the population contributing to the
LFP~\cite{MannEtal09}.  Because SuperEEG reconstructs LFPs throughout
the brain, one could in principle use gamma or broadband power in the
reconstructed signals to estimate the corresponding firing rates
(though not the timings of individual action potentials).

Beyond providing a means of estimating ongoing activity throughout the
brain using already implanted electrodes, our work also has
implications for where to place the electrodes in the first place.
Electrodes are typically implanted to maximize coverage of suspected
epileptogenic tissue.  However, our findings suggest that this approach
could be further optimized.  Specifically, one could leverage not only
the non-invasive recordings taken during an initial monitoring period
(as is currently done), but also recordings collected from other
patients.  We could then ask: given everything we know about the other
patients and from the scalp recordings of this new patient, where
should we place a fixed number of electrodes to maximize our ability
to map seizure foci?  As shown in Figure~\ref{fig:informap}, recordings
from different locations are differently informative in terms of
reconstructing the spatiotemporal patterns throughout the brain.
This property might be leveraged in decisions about where to
surgically implant electrodes in future patients.

%%%%

\section*{Introduction}
% JRM thoughts:
% - Tie in stats from supplemental analyses.  Fig S4: total number of
% electrodes, total number of used electrodes, prop thresholded, total
% recording time, average session time, number of sessions.


(i.e.,
relying on a combination of volume conductance


(Across shown in black, see Fig.~\ref{fig:corrmap}A). We also
reconstructed activity for each electrode using a model trained on the
remaining electrodes from only that patient, to account for
reconstruction accuracy attributed to volume conductance alone (Within
shown in gray, see Fig.~\ref{fig:corrmap}A). For the first dataset, we
compared these two distributions of correlation coefficients (paired
$t$-test between $z$-transformed mean correlation coefficients by
patient: $t(66) = 9.64, p < 10\textsuperscript{-10}$).  We repeated
this analysis on a similar dataset Fig.~\ref{fig:corrmap}C) with
similar results (paired $t$-test between $z$-transformed mean
correlation coefficients by patient:
$t(23) = 6.93, p < 10\textsuperscript{-5}$). This is an especially
conservative test, given that the SuperEEG reconstructions exclude
(from the correlation matrix estimates) all data from the patient
whose data is being reconstructed.  Furthermore, we also replicated
this finding for each independent experiment within dataset 2 (Fig. S3
(paired $t$-test between $z$-transformed mean correlation coefficients
by patient for experiment 1:
$t(23) = 6.23, p < 10\textsuperscript{-5}$ and experiment 2:
$t(23) = 6.62, p < 10\textsuperscript{-5}$).

%%%

Current human brain recording techniques are fraught with compromise.
Commonly used approaches include functional magnetic resonance imaging
(fMRI), scalp electroencephalography (EEG), and magnetoencephalography
(MEG).  For each of these techniques, neuroscientists
and electrophysiologists must choose to optimize spatial resolution
at the cost of temporal resolution (e.g.\ as in fMRI) or temporal
resolution at the cost of spatial resolution (e.g.\ as in EEG
and MEG).  A less widely used approach (due to requiring work with
neurosurgical patients) is to record from electrodes implanted
directly onto the cortical surface (electrocorticography; ECoG) or
into deep brain structures (intracranial EEG; iEEG).  However, these
intracranial approaches also require compromise: the high temporal and
spatial resolutions of intracranial recordings comes at the cost of
substantially reduced brain coverage, since safety considerations
limit the number of electrodes one may implant in a given patient's
brain.  Further, the locations of implanted electrodes are determined by clinical,
rather than research, needs.

%Beamforming: huge advance for scalp recordings, but the inverse
%problem is fundamentally ambiguous.  This limits the precision with
%which one can measure activity from deep brain structures.
An increasingly popular approach is to improve the effective spatial resolution
of MEG or scalp EEG data by using a geometric approach called
\textit{beamforming} to solve the biomagnetic or bioelectrical inverse
problem~\cite{Sarv87}.  This approach entails using detailed brain
conductance models (often informed by high spatial resolution
anatomical MRI images) along with the known sensor placements
(localized precisely in 3D space) to reconstruct brain signals
originating from theoretical point sources deep in the brain (and far
from the sensors).  Traditional beamforming approaches must overcome
two obstacles.  First, the inverse problem beamforming seeks to solve
has infinitely many solutions.  Researchers have made traction towards
constraining the solution space by assuming that signal-generating
sources are localized on a regularly spaced grid spanning the brain
and that individual sources are small relative to their distances to
the sensors~\cite{Snyd91, BailEtal01, HillEtal05}.  The second, and in
some ways much more serious, obstacle is that the magnetic fields
produced by external (noise) sources are substantially stronger than
those produced by the neuronal changes being sought (i.e.\ at deep structures, as measured by sensors at the scalp).  This means that
obtaining adequate signal quality often requires averaging the measured
responses over tens to hundreds of responses or trials (e.g. see
review by~\cite{HillEtal05}).

Another approach to obtaining high spatial and temporal resolution
neural data has been to collect fMRI and EEG data simultaneously.
Simultaneous fMRI-EEG has the potential to balance the high spatial
resolution of fMRI with the high temporal resolution of scalp EEG,
thereby, in theory, providing the best of both worlds.  In practice,
however, the signal quality of both recordings suffers substantially
when the two techniques are applied simultaneously (e.g. see review
by~\cite{HustEtal12}).  In addition, the experimental designs that are
ideally suited to each technique individually are somewhat at odds.
For example, fMRI experiments typically lock stimulus presentation
events to the regularly spaced image acquisition time (TR), which
maximizes the number of post-stimulus samples.  By contrast, EEG
experiments typically employ jittered stimulus presentation times to
maximize the experimentalist's ability to distinguish electrical brain
activity from external noise sources such as from 60 Hz alternating
current power sources.

%Direct intracranial recordings are the gold standard method for
%measuring activity from deep brain structures in both humans and
%animals.
%However, one can only implant a limited number of electrodes in a
%given person's brain.  This begs the question: what can we infer
%about the activity exhibited by the rest of that person's brain,
%given what we learn from recordings taken from \textit{other people's
%brains}?
The current ``gold standard'' for precisely localizing signals and
sampling at high temporal resolution is to take (ECoG or iEEG)
recordings from implanted electrodes (but from a limited set of
locations in any given brain).  This begs the following question: what
can we infer about the activity exhibited by the rest of a person's
brain, given what we learn from the limited intracranial recordings we
have from their brain and additional recordings taken from
\textit{other} people's brains?  Here we develop an approach, based on
Gaussian process regression~\cite{Rasm06}, that uses data from
multiple people to estimate activity at arbitrary
locations in each person's brain (i.e., independent of their electrode
placements).  We test this \textit{Super EEG} approach using a large
dataset of intracranial recordings collected as neurosurgical patients
studied and recalled random word lists~\cite{SedeEtal03, SedeEtal07a,
  SedeEtal07b, MannEtal11, MannEtal12}.  We show that the Super EEG
algorithm recovers signals well from electrodes that were held out of
the training dataset.  We also examine the factors that influence how
accurately activity may be estimated (recovered), which may have important
implications for electrode design and for electrode placement in
neurosurgical applications.

%%%%%



  The correlational structure of functional neuroimaging data may be
  used to predict which moment of movie or story an individual is
  experiencing, identify which person's brain a recording came from,
  and identify the task a person is performing.  In contrast, our
  structural (anatomical) connectome is static for the duration of
  typical neuroimaging experiments, is task invariant, and is similar
  across people.  How might these seemingly opposing features of
  functional connectomes versus static structural connectomes be
  reconciled?  We developed a static task- and person-invariant
  connectome model, and explored the extent to which the model could
  explain dynamic full-brain activity patterns.  We trained the model
  using ECoG recordings from two large datasets, and we tested its
  ability to predict held-out data.  We found that neural activity
  patterns are best explained by a connectome that is common across
  individuals, but changes across tasks.




Are our brain's networks static or dynamic?  And to what extent are the network properties of our brains stable across people and tasks?  One body of work suggests that our brain's \textit{functional} networks are dynamic~\citep[e.g., ][]{MannEtal18}, person-specific~\citep[e.g., ][]{FinnEtal15}, and task-specific~\citep[e.g., ][]{Turk13}.  In contrast, although the gross anatomical structure of our brains changes meaningfully over the course of years as our brains develop, on the timescales of typical neuroimaging experiments (i.e., hours to days) our anatomical networks are largely stable~\citep[e.g., ][]{CaseEtal00}.  Further, many aspects of brain anatomy, including white matter structure, is largely preserved across people~\citep[e.g., ][]{TalaTour88, JahaEtal13, MoriEtal08}  There are several possible means of reconciling this apparent inconsistency between dynamic person- and task-specific functional networks versus stable anatomical networks.  For example, relatively small magnitude anatomical differences across people may be reflected in reliable functional connectivity differences.  Along these lines, one recent study found that diffusion tensor imaging (DTI) structural data is similar across people, but may be used to predict person-specific resting state functional connectivity data~\citep{BeckEtal18}.  Another (potentially complementary) possibility is that our functional networks are constrained by anatomy, but nevertheless exhibit rapid task-dependent changes~\citep[e.g., ][]{SporBetz16}.

Here we take a model-based approach to studying whether high
spatiotemporal resolution activity patterns throughout the human brain
may be explained by a static connectome model that is shared across
people and tasks.  Specifically, we trained a model to take in
recordings from a subset of brain locations, and then predicted
activity patterns during the same interval, but at \textit{other}
locations that were held out from the model.  Our model, based on
Gaussian process regression, relies on three assumptions (each of
which we test).  First, we assume that functional correlations are
stable over time and across tasks.  Second, we assume that some of the
correlational structure of people's brain activity is similar across
individuals.  Third, we resolve ambiguities in the data by assuming
that neural activity from nearby sources will tend to be similar, all
else being equal.  After fitting the model to an ECoG dataset, one can
then ask (for a held-out individual's brain): given what we know about
the correlational structure of \textit{other} people's brains, and
given the recordings we made from electrodes implanted in this
person's brain, how would those recordings most likely have looked at
\textit{other} locations throughout this person's brain?  We named our
general approach \textit{SuperEEG} because the trained model provides
a means of inferring full-brain activity patterns at high
spatiotemporal resolutions, using ECoG recordings taken from a limited
set of brain locations.

We tested the SuperEEG approach using two large ECoG datasets. Dataset 1 comprises multi-hour recordings from 6876 electrodes taken across several recording sessions as 88 neurosurgical patients studied random word lists periodically throughout their day~\cite{SedeEtal03, SedeEtal07a,
  SedeEtal07b, MannEtal11, MannEtal12}.  Dataset 2 comprises recordings from XXX electrodes taken as XXX patients performed a series of two memory tasks~\citep{EzzyEtal17, HoraEtal17, KragEtal17, KuceEtal17, LinEtal17, SoloEtal18, WeidEtal18, EzzyEtal18, KuceEtal18}.  In both datasets,
  we compared the predictions made using models trained across people to predictions made using within-person data.  We found that models that incorporate data from other patients yield far more reliable predictions about an individual patient's brain activity patterns than models trained solely on that individual's data.  This indicates that at least some functional correlations are common across people.  We also used Dataset 2 to compare predictions made using data from within task, across task, or combining within and across task data.  We found that all three approaches yielded reliable predictions, but the within task predictions were the most accurate.  This indicates that some aspects of our functional connectomes are common across tasks, whereas other aspects are task-specific.  Finally, all of the models we trained (within and across patients and tasks) assumed a static connectome and yielded above-chance accuracy.  This indicates that despite moment-by-moment fluctuations in the functional connectome, at least some aspects of our connectome appear to be stable over the course of several hours.

%%%%%





, the gross \textit{structural} aspects of our brain are essentailly static over the timescales of typical experiments (on the order of

Current human brain recording techniques are fraught with compromise.
Commonly used approaches include functional magnetic resonance imaging
(fMRI), scalp electroencephalography (EEG), and magnetoencephalography
(MEG).  For each of these techniques, neuroscientists
and electrophysiologists must choose to optimize spatial resolution
at the cost of temporal resolution (e.g.\ as in fMRI) or temporal
resolution at the cost of spatial resolution (e.g.\ as in EEG
and MEG).  A less widely used approach (due to requiring work with
neurosurgical patients) is to record from electrodes implanted
directly onto the cortical surface (electrocorticography; ECoG) or
into deep brain structures (intracranial EEG; iEEG).  However, these
intracranial approaches also require compromise: the high temporal and
spatial resolutions of intracranial recordings come at the cost of
substantially reduced brain coverage, since safety considerations
limit the number of electrodes one may implant in a given patient's
brain.  Further, the locations of implanted electrodes are determined by clinical,
rather than research, needs.

%Beamforming: huge advance for scalp recordings, but the inverse
%problem is fundamentally ambiguous.  This limits the precision with
%which one can measure activity from deep brain structures.
An increasingly popular approach is to improve the effective spatial resolution
of MEG or scalp EEG data by using a geometric approach called
\textit{beamforming} to solve the biomagnetic or bioelectrical inverse
problem~\cite{Sarv87}.  This approach entails using detailed brain
conductance models (often informed by high spatial resolution
anatomical MRI images) along with the known sensor placements
(localized precisely in 3D space) to reconstruct brain signals
originating from theoretical point sources deep in the brain (and far
from the sensors).  Traditional beamforming approaches must overcome
two obstacles.  First, the inverse problem beamforming seeks to solve
has infinitely many solutions.  Researchers have made traction towards
constraining the solution space by assuming that signal-generating
sources are localized on a regularly spaced grid spanning the brain
and that individual sources are small relative to their distances to
the sensors~\cite{Snyd91, BailEtal01, HillEtal05}.  The second, and in
some ways much more serious, obstacle is that the magnetic fields
produced by external (noise) sources are substantially stronger than
those produced by the neuronal changes being sought (i.e.\ at deep structures, as measured by sensors at the scalp).  This means that
obtaining adequate signal quality often requires averaging the measured
responses over tens to hundreds of responses or trials (e.g. see
review by~\cite{HillEtal05}).

Another approach to obtaining high spatial and temporal resolution
neural data has been to collect fMRI and EEG data simultaneously.
Simultaneous fMRI-EEG has the potential to balance the high spatial
resolution of fMRI with the high temporal resolution of scalp EEG,
thereby, in theory, providing the best of both worlds.  In practice,
however, the signal quality of both recordings suffers substantially
when the two techniques are applied simultaneously (e.g. see review
by~\cite{HustEtal12}).  In addition, the experimental designs that are
ideally suited to each technique individually are somewhat at odds.
For example, fMRI experiments typically lock stimulus presentation
events to the regularly spaced image acquisition time (TR), which
maximizes the number of post-stimulus samples.  By contrast, EEG
experiments typically employ jittered stimulus presentation times to
maximize the experimentalist's ability to distinguish electrical brain
activity from external noise sources such as from 60 Hz alternating
current power sources.

%Direct intracranial recordings are the gold standard method for
%measuring activity from deep brain structures in both humans and
%animals.
%However, one can only implant a limited number of electrodes in a
%given person's brain.  This begs the question: what can we infer
%about the activity exhibited by the rest of that person's brain,
%given what we learn from recordings taken from \textit{other people's
%brains}?
The current ``gold standard'' for precisely localizing signals and
sampling at high temporal resolution is to take (ECoG or iEEG)
recordings from implanted electrodes (but from a limited set of
locations in any given brain).  This begs the following question: what
can we infer about the activity exhibited by the rest of a person's
brain, given what we learn from the limited intracranial recordings we
have from their brain and additional recordings taken from
\textit{other} people's brains?  Here we develop an approach, based on
Gaussian process regression~\cite{Rasm06}, that uses data from
multiple people to estimate activity at arbitrary
locations in each person's brain (i.e., independent of their electrode
placements).  We test this \textit{Super EEG} approach using two large
datasets of intracranial recordings collected as neurosurgical patients
studied and recalled random word lists~\cite{SedeEtal03, SedeEtal07a,
  SedeEtal07b, MannEtal11, MannEtal12}.  We show that the Super EEG
algorithm recovers signals well from electrodes that were held out of
the training dataset.  We replicate this finding using a second dataset, which contains data from two experiments for each patient, allowing us to also probe the task-specific contributions to reconstruction accuracy.  Additionally, we examine the factors that influence how
accurately activity may be estimated (recovered), which may have important
implications for electrode design and for electrode placement in
neurosurgical applications.

Further, if some aspects of our connectomes are static, can we use them to fill in ``missing'' data?  In other words, given recordings from a subset of brain locations, how reliably can activity patterns from the rest of the brain be inferred using an estimated static connectome?  And to what extent can those


Human \textit{Super EEG}\footnote{The term ``Super EEG'' was
coined by Robert J. Sawyer in his popular science fiction novel
\textit{The Terminal Experiment}~\cite{Sawy95}} entails
measuring ongoing activity from every cell in a living human brain
at millisecond-scale temporal resolutions.  Although direct
cell-by-cell Super EEG recordings are impossible using existing
methods, here we present a technique for \textit{inferring} neural
activity at millimeter-scale spatial resolutions and millisecond-scale temporal resolutions by fitting a model to existing human intracranial electrophysiological recordings.  Our approach, based
on Gaussian process regression, relies on two assumptions.  First,
we assume that some of the correlational structure of people's
brain activity is similar across individuals.  Second, we resolve
ambiguities in the data by assuming that neural activity from
nearby sources will tend to be similar, all else being equal.  One
can then ask, for an arbitrary individual's brain: given what we
know about the correlational structure of \textother people's brains,
and given the recordings we made from electrodes implanted in this
person's brain, how would those recordings most likely have looked
at \textit{other} locations throughout this person's brain?  Our work examines a deep neuroscientific question: given recordings for one set of locations from a given person, how much can we infer about activity patterns throughout the rest of the same person's brain as those recordings were taken?

The above finding that activity at densely sampled brain areas can be
(slightly) better reconstructed than at sparsely sampled brain areas
could have important implications for patient surgeries.  For example,
when implanting electrodes into new patients, perhaps those electrodes
should target regions

we hypothesized might influence the quality of the
data reconstructions is the

Whereas the above analyses show that the Super EEG algorithm may be
used to estimate time-varying LFPs throught the brain using data from a small
number of implanted electrodes,

Having established that data within and across patients may be used to
accurately estimate neural recordings from unsampled locations, we
next wondered whether certain electrode placements might be especially
informative to these estimates.

We also carried out an analogous analysis
across patients by comparing the average correlation coefficients from
each patient obtained using Super EEG versus using the nearest
neighbor's voltages ($t(XXX) = XXX, p = XXX$).

%average correlation by nearest within-subject and across-subject electrode
%distance

%average correlation by holding out electrodes at various distances
%within subject (include none and all).  note that the all case can
%only be included for the covariance estimation; for the final
%reconstruction step that datapoint should be separate (on the plot)
%and should indicate reconstruction correlation using just the
%furthest-away electrode.

%map showing how informative each location is: if you include
% electrodes within a searchlight surrounding the location vs. don't
% include them, how substantially do the average reconstruction
% correlations change?  use k-means clustering to find sets of
% electrodes whose correlation change profiles group together, and
% pick the electrode with the highest correlation difference within
% each set.  (show maps of each correlation profile.)  show the
% average reconstruction correlation as a function of the numbers of
% electrodes near these regions.  this can be used to suggest
% electrode placements for the best accuracy.

%maybe there's a dataset I could use that includes single neuron
%recordings?  I could use broadband LFPs to predict firing rates.



%The preceding analyses elucidate how the quality of the Super EEG
%algorithm's estimates varies with spatial location, and how the
%predictive power of the recordings vary with spatial location.  In
%addition to the spatial properties of the electrodes, the temporal
%resolutions of the recordings can vary substantially from patient to
%patient (e.g. according to the sampling rate of each hospital's
%clinical recording hardware).  In the above analyses, each patients'
%data were reconstructed at the sampling rates of their original
%recordings.  However, these across-patient differences in sampling
%rates could affect the degrees to which different features of the
%underlying neural activity were reflected in the recordings.  For
%example, high frequency oscillations could not be measured in low
%temporal resolution recordings, whereas they may be measured using
%high temporal resolution recordings.  In turn, this could affect the
%estimates of how different brain structures were interacting, such
%that the estimates contributed by some patients' data would be driven
%by high frequency activity that was not present in other patients'
%data due to differences in sampling rates.





% To evaluate the quality of the reconstruction of a given
% electrode from a given patient $s$, we computed the average Pearson's
% correlation (across recording sessions) between the Super
% EEG-reconstructed voltage trace, $\hat{Y}_{s,k}$, and the observed
% voltage trace, $Y_{s,k}$ at that location (specifically, the corresponding
% columns of those matrices).  (Note that here $k$ denotes the recording
% session number.)  In other words, we computed $\hat{Y}_{s,k,\beta}$
% using Equations~\ref{eqn:Kba}, \ref{eqn:Kaa}, and
% \ref{eqn:reconstruction}, but we treated the to-be-reconstructed
% electrode location $i$ as a member of $\beta$ (the unobserved set of
% recording locations) rather than as a member of $\alpha$ (the observed
% set of recording locations).

We present a method for inferring local field potentials throughout the brain from recordings at a limited number sites.

Methods overview. Electrode
      locations.  Each dot reflects the location of a single
    electrode in the dataset.  One patient's electrode locations are
    highlighted in red and the to-be-reconstructed recording location
    is highlighted in blue. \textbf{B. Radial basis function (RBF).}
    Each electrode contributed by the patient (red) weights on the
    full set of locations under consideration (all dots in panel A,
    defined as $\bar{R}$ in the text).  The weights fall off with
    positional distance (in MNI space) according to an RBF.
    \textbf{C. Per-patient correlation matrices.}  After computing the
    pairwise correlations between the recordings from each patient's
    electrodes, we use RBF-weighted averages to estimate correlations
    between all locations in $\bar{R}$.  We obtain an estimated
    full-brain correlation matrix using each patient's
    data. \textbf{D.  Combined correlation matrix.}  We estimate a
    single full-brain correlation matrix by averaging
    the patient-specific correlation matrices.  \textbf{E.
      Reconstructing ``missing'' activity.}  Given the observed
    activity from the patient's electrodes and the estimated
    correlation matrix (Panel D), we can compute a maximum likelihood
    estimate of the voltage trace at any location in $\bar{R}$.  An
    example reconstruction (at the blue dot in Panel A) is shown in
    gray.

% Across all electrodes, from all patients, the correlations between
% observed and estimated activity were reliably greater than 0
% (Fig.~\ref{fig:corrmap}B; $t(4148) = 107, p < 10^{-10}$; $t$-test on
% the distribution of $z$-transformed correlation
% coefficients). Furthermore, across patients the average correlations
% between observed and estimated activity were also reliably greater
% than 0 $(t(66) = 23.3, p < 10^{-10}$; $t$-test on the distribution of
% averaged $z$-transformed correlation coefficients for each patient).
% Overall, these analyses suggest that data from held-out electrodes may
% be reliably estimated using Super EEG.

% %%% should the remaining equations be in this section or in the methods?
% Finally, we wished to infer activity at all locations in the standard MNI152 brain. First, we calculate the location similarity $\theta$ between each voxel location in the standard MNI152 brain $i$ and every location $j \in \bar{R}$. With this similarity value, we can create a map in MNI space by interpolating a correlation value $\hat{\rho}$ at every voxel $i$ using the corresponding correlation value $\rho$ at each location in $\bar{R}$ with the following equations:

% \begin{align}
% \hat{\rho}(i) &= \mathrm{r}\left\{\frac{\sum_{j=1}^{|\bar{R}|}\theta(i,j)\cdot\mathrm{z}(\rho(i))}{\sum_{j=1}^{|\bar{R}|}\theta(i,j)} \right\}, \mathrm{where}\\
% \theta(i,j) &= \mathrm{exp} \left\{-||i-j||^2\right\}.\\
% \end{align}

% As mentioned above, the reconstruction procedure for $\hat{Y}_i$ cannot account
% for across-electrode impedance differences, so the estimates will be
% off by a constant scaling factor.

% % already mention this above...

% the next section addresses 'patient 1' and 'electrode 1'... keep this way of describing??


% We also used a permutation-based procedure to assess which
% correlations were both positive and statistically reliable (see
% \textit{Supplemental Methods}).


One potential application of the Super EEG algorithm is localizing
seizures.  For example, whereas examining recordings from implanted
electrodes can yield insights into which electrode is closest to where
the seizure was kindled, the Super EEG algorithm could provide a full 3D
map of activity throughout the brain at each moment in time as the
seizure evolves.  However, reconstruction quality



, which we hypothesized might be
related to how

More generally, we can ask about the quality of this type of
reconstruction across all electrodes and patients in the dataset.
Figure~\ref{fig:corrmap}A displays the correlation between the
observed and estimated LFPs as a function of electrode location (i.e.,
holding out each electrode in turn, and comparing the estimated versus
observed data for the held-out electrode).  The map
reveals that the reconstruction quality varies somewhat with the spatial
location being considered.  Specifically, activity at locations that
receive dense electrode coverage within and across patients
(e.g. medial temporal lobe) is estimated more accurately than activity
at sparsely sampled locations (Fig.~\ref{fig:density}B).
